import requests
import json
import re

# ================= é…ç½®åŒºåŸŸ =================
# è¯·åŠ¡å¿…å¡«å…¥ä½ æ­£åœ¨ä½¿ç”¨çš„ Key
API_KEY = "sk-aonzxraxsctwtfshddtbaytnqpikuwssvhendbhhizohiaol" 

# ä½ çš„æ ¡å†… API åœ°å€
URL = "https://api.siliconflow.cn/v1/chat/completions"

# æ¨¡å‹åç§° (å»ºè®®å…ˆç”¨ deepseek-chat æµ‹è¯•ï¼Œå› ä¸ºå®ƒå¬è¯)
MODEL_NAME = "Qwen/Qwen2.5-32B-Instruct" 
# ===========================================

def test_decision_capability():
    print(f"ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨è¯Šæ–­ API å†³ç­–èƒ½åŠ›...")
    print(f"ç›®æ ‡ URL: {URL}")
    print(f"ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
    print("-" * 50)

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }

    # æ„é€ ä¸€ä¸ªâ€œæåº¦è¯±å¯¼åˆä½œâ€çš„åœºæ™¯
    # å¦‚æœåœ¨è¿™ä¸ªåœºæ™¯ä¸‹ LLM éƒ½ä¸å›å¤ 1ï¼Œé‚£è¯´æ˜æœ‰é—®é¢˜
    test_prompt = (
        "å½“å‰æ˜¯ç¬¬ 1 å›åˆã€‚\n"
        "ä½ æœ‰ 5 ä¸ªé‚»å±…ï¼Œä¸Šä¸€è½®è¿™ 5 ä¸ªäººã€å…¨éƒ¨ã€‘é€‰æ‹©äº†åˆä½œã€‚\n"
        "å¦‚æœä½ é€‰æ‹©åˆä½œï¼Œå¤§å®¶éƒ½èƒ½èµšå¤§é’±ã€‚\n"
        "ä½ ä¼šåˆä½œå—ï¼Ÿ\n"
        "**è¯·ä»…å›å¤æ•°å­— '1' (ä»£è¡¨åˆä½œ) æˆ– '0' (ä»£è¡¨èƒŒå›)**ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ã€‚"
    )

    data = {
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç†æ€§çš„åšå¼ˆç©å®¶ã€‚è¯·ä¸¥æ ¼éµå¾ªè¾“å‡ºæ ¼å¼ã€‚"},
            {"role": "user", "content": test_prompt}
        ],
        "model": MODEL_NAME,
        "temperature": 0.1, # æä½æ¸©åº¦ï¼Œå¼ºè¿«å®ƒå¬è¯
        "stream": False
    }

    try:
        response = requests.post(URL, headers=headers, json=data, timeout=60)
        
        print(f"ğŸ“¡ HTTP çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            # 1. æ‰“å°åŸå§‹å®Œæ•´å›å¤
            raw_content = result["choices"][0]["message"]["content"]
            print(f"\nğŸ“ [é‡è¦] LLM åŸå§‹å›å¤å†…å®¹:\n{'-'*20}\n{raw_content}\n{'-'*20}")
            
            # 2. æ¨¡æ‹Ÿ llm_bots.py é‡Œçš„æ¸…æ´—é€»è¾‘
            clean_content = raw_content.strip()
            if "</think>" in clean_content:
                clean_content = clean_content.split("</think>")[-1].strip()
            
            print(f"ğŸ§¹ æ¸…æ´—åå†…å®¹: [{clean_content}]")
            
            # 3. æ¨¡æ‹Ÿ llm_bots.py é‡Œçš„æå–é€»è¾‘
            digits = re.findall(r'\b[01]\b', clean_content)
            print(f"ğŸ” æ­£åˆ™æå–ç»“æœ: {digits}")
            
            if digits:
                final_action = int(digits[0])
                print(f"âœ… æœ€ç»ˆåˆ¤å®šåŠ¨ä½œ: {final_action} ({'åˆä½œ' if final_action==1 else 'èƒŒå›'})")
            else:
                print("âŒ æå–å¤±è´¥ï¼ä»£ç å°†é»˜è®¤ä¸º 0 (èƒŒå›)ã€‚")
                print("   -> åŸå› å¯èƒ½æ˜¯ LLM å›å¤äº†å¤šä½™çš„æ ‡ç‚¹æˆ–æ–‡å­—ï¼Œå¯¼è‡´æ­£åˆ™ä¸åŒ¹é…ã€‚")
        else:
            print(f"âŒ API è¯·æ±‚å¤±è´¥: {response.text}")

    except Exception as e:
        print(f"âŒ å‘ç”Ÿå¼‚å¸¸: {e}")

if __name__ == "__main__":
    test_decision_capability()